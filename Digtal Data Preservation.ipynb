{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d60910b-eb58-44f0-b7bd-b78d9581dffc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Big Data Analytics Framework for Efficient Management & Preservation of Digital Archives & Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea59c85",
   "metadata": {},
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e0814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python --index-url=https://pypi.python.org/simple/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f1205",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install moviepy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5a325",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e7c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a152fc",
   "metadata": {},
   "source": [
    "**Data Sorting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e641b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_and_move_files(directory_path):\n",
    "    # Define folder names\n",
    "    video_folder = 'videos'\n",
    "    pdf_folder = 'pdfs'\n",
    "    images_folder = 'images'\n",
    "    unclassified_folder = 'unclassified'\n",
    "\n",
    "    # Create folders if they don't exist\n",
    "    folders = [video_folder, pdf_folder, images_folder, unclassified_folder]\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(directory_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Check if it's a file\n",
    "        if os.path.isfile(file_path):\n",
    "            # Get the file extension\n",
    "            _, file_extension = os.path.splitext(filename)\n",
    "\n",
    "            # Categorize files based on extension\n",
    "            if file_extension.lower() in ['.mp4', '.avi', '.mkv', '.dat']:\n",
    "                destination_folder = video_folder\n",
    "            elif file_extension.lower() == '.pdf':\n",
    "                destination_folder = pdf_folder\n",
    "            elif file_extension.lower() in ['.jpg', '.jpeg', '.png', '.gif']:\n",
    "                destination_folder = images_folder\n",
    "            else:\n",
    "                destination_folder = unclassified_folder\n",
    "\n",
    "            # Move the file to the corresponding folder\n",
    "            destination_path = os.path.join(directory_path, destination_folder, filename)\n",
    "            shutil.move(file_path, destination_path)\n",
    "            print(f\"Moved {filename} to {destination_folder} folder.\")\n",
    "\n",
    "            \n",
    "directory_path = './data'\n",
    "categorize_and_move_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db55d31",
   "metadata": {},
   "source": [
    "**Video Data Reading/Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac97be22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get video features\n",
    "def get_video_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get number of frames and resolution\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    resolution = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    frame_rate = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # Calculate duration using number of frames and frame rate\n",
    "    duration = num_frames / frame_rate if frame_rate > 0 else 0\n",
    "    # Get codec information\n",
    "    codec_fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    codec = chr(codec_fourcc & 0xFF) + chr((codec_fourcc & 0xFF00) >> 8) + chr((codec_fourcc & 0xFF0000) >> 16) + chr((codec_fourcc & 0xFF000000) >> 24)\n",
    "\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return num_frames, resolution, duration, frame_rate, codec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af6f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "directory_path = './data/videos'\n",
    "\n",
    "# Ensure the directory path is valid\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(\"Invalid directory path.\")\n",
    "else:\n",
    "    # Initialize an empty list to store file information\n",
    "    file_info_list = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Check if it's a file\n",
    "        if os.path.isfile(file_path):\n",
    "            # Extract filename, extension, and filepath\n",
    "            file_info = {\n",
    "                'filename': os.path.splitext(filename)[0],  # Store filename without extension\n",
    "                'extension': os.path.splitext(filename)[1],\n",
    "                'filepath': os.path.normpath(file_path)  # Normalize file path\n",
    "            }\n",
    "            # Get video information\n",
    "            num_frames, resolution, duration, frame_rate, codec = get_video_info(file_path)\n",
    "            file_info['num_frames'] = num_frames\n",
    "            file_info['resolution'] = resolution\n",
    "            file_info['duration'] = duration\n",
    "            file_info['frame_rate'] = frame_rate\n",
    "            file_info['codec'] = codec\n",
    "\n",
    "            \n",
    "            \n",
    "            file_info_list.append(file_info)\n",
    "\n",
    "    # Create a DataFrame from the list of file information\n",
    "    video_file_info_df = pd.DataFrame(file_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "video_file_info_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10d02bf",
   "metadata": {},
   "source": [
    "**Data Extraction From Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import speech_recognition as sr\n",
    "import tempfile\n",
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "# Function to extract audio from video file using moviepy\n",
    "def extract_audio(video_file):\n",
    "    video_clip = VideoFileClip(video_file)\n",
    "    audio_clip = video_clip.audio\n",
    "    return audio_clip\n",
    "\n",
    "def chunk_audio_and_save(audio_path, chunk_length=5000):  # chunk_length in milliseconds\n",
    "    audio = AudioSegment.from_wav(audio_path)\n",
    "    length_audio = len(audio)\n",
    "    chunk_paths = []\n",
    "    for i, chunk in enumerate(range(0, length_audio, chunk_length)):\n",
    "        chunk_audio = audio[chunk:chunk + chunk_length]\n",
    "        chunk_path = f\"./temp_chunk_{i}.wav\"\n",
    "        chunk_audio.export(chunk_path, format=\"wav\")\n",
    "        chunk_paths.append(chunk_path)\n",
    "    return chunk_paths\n",
    "\n",
    "# Function to convert audio to text using SpeechRecognition\n",
    "def audio_to_text(filename, audio_file):\n",
    "    audio_file_name = f'./audio/{filename}.wav'\n",
    "    audio_file.write_audiofile(audio_file_name)\n",
    "    chunk_file_paths = chunk_audio_and_save(audio_file_name)\n",
    "    # Initialize recognizer \n",
    "    r = sr.Recognizer() \n",
    "    text = \"\"\n",
    "    \n",
    "    for i, file_path in enumerate(chunk_file_paths):\n",
    "        print(f\"Transcribing chunk {i+1}/{len(chunk_file_paths)}...\")\n",
    "        # Load the audio file \n",
    "        with sr.AudioFile(file_path) as source: \n",
    "            data = r.record(source) \n",
    "\n",
    "        # Convert speech to text \n",
    "        part_text = r.recognize_google(data)\n",
    "        text += part_text\n",
    "        os.remove(file_path)  # Clean up chunk file\n",
    "\n",
    "    return text\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for index, row in video_file_info_df.iterrows():\n",
    "    # Check if it's a video file (.mp4, .dat)\n",
    "    if row['extension'].lower() in ['.mp4', '.dat']:\n",
    "        try:\n",
    "            video_path = \"./\" + row['filepath'].replace('\\\\', '/')\n",
    "            print(video_path)\n",
    "            # Extract audio from video\n",
    "            audio_clip = extract_audio(video_path)\n",
    "\n",
    "            # Convert audio to text\n",
    "            audio_text = audio_to_text(row['filename'], audio_clip)\n",
    "\n",
    "            # Update 'audio_text' column in the DataFrame\n",
    "            video_file_info_df.at[index, 'audio_text'] = audio_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row['filename']}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame\n",
    "video_file_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbbf62",
   "metadata": {},
   "source": [
    "**Image Data Reading/Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f777a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate image noise \n",
    "def calculate_noise(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    noise = cv2.meanStdDev(gray)[1][0]\n",
    "    return noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f3fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get dominant color\n",
    "def get_dominant_color(image):\n",
    "    # Reshape image to a list of pixels\n",
    "    pixels = image.reshape((-1, 3))\n",
    "\n",
    "    # Calculate histogram\n",
    "    hist = np.histogramdd(pixels, bins=(256, 256, 256), range=[(0, 256), (0, 256), (0, 256)])[0]\n",
    "\n",
    "    # Find the dominant color\n",
    "    dominant_color = np.unravel_index(np.argmax(hist), hist.shape)\n",
    "\n",
    "    return dominant_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1231402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text using OCR\n",
    "def extract_text(image_path):\n",
    "    # Read the image using Pillow (PIL)\n",
    "    img_pil = Image.open(image_path)\n",
    "\n",
    "    # Perform OCR using Tesseract\n",
    "    text = pytesseract.image_to_string(img_pil)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e11af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get image information\n",
    "def get_image_info(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Get basic image information\n",
    "    filename = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    extension = os.path.splitext(image_path)[1]\n",
    "    resolution = img.shape[:2]\n",
    "    num_pixels = img.size\n",
    "    is_grayscale = len(img.shape) < 3\n",
    "    noise = calculate_noise(img)\n",
    "    size = os.path.getsize(image_path)\n",
    "    \n",
    "    mean_intensity = img.mean()\n",
    "    std_intensity = img.std()\n",
    "    min_intensity = img.min()\n",
    "    max_intensity = img.max()\n",
    "    \n",
    "    # Color channels\n",
    "    num_channels = img.shape[2] if len(img.shape) == 3 else 1\n",
    "\n",
    "    # Dominant color\n",
    "    dominant_color = get_dominant_color(img)\n",
    "\n",
    "    # Aspect ratio\n",
    "    aspect_ratio = resolution[0] / resolution[1] if resolution[1] != 0 else 0\n",
    "    \n",
    "    # Extract text using OCR\n",
    "    text = extract_text(image_path)\n",
    "\n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'extension': extension,\n",
    "        'filepath': os.path.normpath(image_path),\n",
    "        'resolution': resolution,\n",
    "        'num_pixels': num_pixels,\n",
    "        'is_grayscale': is_grayscale,\n",
    "        'noise': noise,\n",
    "        'size': size,\n",
    "        'mean_intensity': mean_intensity,\n",
    "        'std_intensity': std_intensity,\n",
    "        'min_intensity': min_intensity,\n",
    "        'max_intensity': max_intensity,\n",
    "        'num_channels': num_channels,\n",
    "        'dominant_color': dominant_color,\n",
    "        'aspect_ratio': aspect_ratio,\n",
    "        'text': text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79452d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "directory_path = './data/images'\n",
    "\n",
    "# Ensure the directory path is valid\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(\"Invalid directory path.\")\n",
    "else:\n",
    "    # Initialize an empty list to store file information\n",
    "    file_info_list = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        image_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Check if it's an image file\n",
    "        if os.path.isfile(image_path) and any(image_path.lower().endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif']):\n",
    "            # Get image information\n",
    "            image_info = get_image_info(image_path)\n",
    "            file_info_list.append(image_info)\n",
    "\n",
    "    # Create a DataFrame from the list of file information\n",
    "    image_file_info_df = pd.DataFrame(file_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091900ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "image_file_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_info_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_info_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56de71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_info_df['extension'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d29c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by extension and calculate average size and number of pixels\n",
    "group_by_extension = image_file_info_df.groupby('extension').agg({\n",
    "    'size': 'mean',\n",
    "    'num_pixels': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "group_by_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a869dae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "X = image_file_info_df[['size', 'num_pixels', 'mean_intensity', 'num_channels']]\n",
    "y = image_file_info_df['is_grayscale']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate accuracy\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Display metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd9b80",
   "metadata": {},
   "source": [
    "**Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histogram for image size\n",
    "image_file_info_df['size'].hist(bins=20)\n",
    "plt.title('Histogram of Image Sizes')\n",
    "plt.xlabel('Size (bytes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Box plot for image size\n",
    "sns.boxplot(x=image_file_info_df['size'])\n",
    "plt.title('Box Plot of Image Sizes')\n",
    "plt.xlabel('Size (bytes)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449dd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation plot\n",
    "correlation_matrix = image_file_info_df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot\n",
    "numerical_features = ['size', 'num_pixels', 'mean_intensity', 'num_channels']\n",
    "sns.pairplot(image_file_info_df[numerical_features])\n",
    "plt.suptitle('Pairplot of Numerical Features', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=image_file_info_df, x='is_grayscale')\n",
    "plt.title('Class Distribution (Grayscale vs. Color)')\n",
    "plt.xlabel('Image Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35cc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatterplot 3D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(image_file_info_df['num_pixels'], image_file_info_df['mean_intensity'], image_file_info_df['size'], c='blue', s=10)\n",
    "ax.set_xlabel('Num Pixels')\n",
    "ax.set_ylabel('Mean Intensity')\n",
    "ax.set_zlabel('Size (bytes)')\n",
    "\n",
    "plt.title('3D Scatter Plot of Numerical Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24ce2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#box plot of image numerical features \n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(data=image_file_info_df, x='is_grayscale', y=feature)\n",
    "    plt.title(f'Box Plot of {feature} by Image Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d421cf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "for i, feature in enumerate(numerical_features, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.violinplot(data=image_file_info_df, x='is_grayscale', y=feature)\n",
    "    plt.title(f'Violin Plot of {feature} by Image Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d44b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=image_file_info_df, x='extension')\n",
    "plt.title('Count of Images by Extension')\n",
    "plt.xlabel('Image Extension')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb6478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "parallel_coordinates(image_file_info_df[numerical_features + ['is_grayscale']], 'is_grayscale', colormap='coolwarm')\n",
    "plt.title('Parallel Coordinates Plot of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ab688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import radviz\n",
    " \n",
    "plt.figure(figsize=(12, 8))\n",
    "radviz(image_file_info_df[numerical_features + ['is_grayscale']], 'is_grayscale', colormap='coolwarm')\n",
    "plt.title('RadViz Plot of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd6d9c1",
   "metadata": {},
   "source": [
    "**Natural Language Processing - NLP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e777c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae2da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba127851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "    # Join tokens back to form processed text\n",
    "    processed_text = ' '.join(tokens)\n",
    "\n",
    "    return processed_text\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "image_file_info_df['processed_text'] = image_file_info_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6255dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with the processed text column\n",
    "image_file_info_df[['text', 'processed_text']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "# Function to plot word frequency\n",
    "def plot_word_frequency(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    freq_dist = FreqDist(tokens)\n",
    "    freq_dist.plot(20, cumulative=False)\n",
    "    plt.title('Top 20 Most Frequent Words')\n",
    "    plt.show()\n",
    "\n",
    "# Apply word frequency analysis to a sample\n",
    "plot_word_frequency(image_file_info_df['processed_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9711b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Function for sentiment analysis\n",
    "def perform_sentiment_analysis(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    return sentiment_scores\n",
    "\n",
    "# Apply sentiment analysis to a sample\n",
    "image_file_info_df['sentiment_scores'] = image_file_info_df['processed_text'].apply(perform_sentiment_analysis)\n",
    "image_file_info_df[['processed_text', 'sentiment_scores']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7114c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, ne_chunk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Function for named entity recognition\n",
    "def extract_named_entities(text):\n",
    "    words = word_tokenize(text)\n",
    "    tagged_words = pos_tag(words)\n",
    "    named_entities = ne_chunk(tagged_words)\n",
    "    return named_entities\n",
    "\n",
    "# Apply named entity recognition to a sample\n",
    "sample_text = image_file_info_df['processed_text'].iloc[0]\n",
    "named_entities = extract_named_entities(sample_text)\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b30aa5",
   "metadata": {},
   "source": [
    "**PDF Data Reading/Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d89f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text content from PDF\n",
    "def get_text_content(doc):\n",
    "    text_content = ''\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        text_content += page.get_text()\n",
    "    return text_content\n",
    "\n",
    "# Function to get the number of images in a PDF\n",
    "def get_num_images(doc):\n",
    "    num_images = 0\n",
    "    for page_num in range(doc.page_count):\n",
    "        page = doc[page_num]\n",
    "        num_images += len(page.get_images(full=True))\n",
    "    return num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get PDF information\n",
    "def get_pdf_info(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    # Get basic PDF information\n",
    "    filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    extension = os.path.splitext(pdf_path)[1]\n",
    "    num_pages = doc.page_count\n",
    "    size = os.path.getsize(pdf_path)\n",
    "\n",
    "    # Additional PDF-related information\n",
    "    text_content = get_text_content(doc)\n",
    "    num_words = len(text_content.split())\n",
    "    num_images = get_num_images(doc)\n",
    "\n",
    "\n",
    "    doc.close()\n",
    "\n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'extension': extension,\n",
    "        'filepath': os.path.normpath(pdf_path),\n",
    "        'num_pages': num_pages,\n",
    "        'size': size,\n",
    "        'text_content': text_content,\n",
    "        'num_words': num_words,\n",
    "        'num_images': num_images\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fa9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory path\n",
    "directory_path = './data/pdfs'\n",
    "\n",
    "# Ensure the directory path is valid\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(\"Invalid directory path.\")\n",
    "else:\n",
    "    # Initialize an empty list to store file information\n",
    "    file_info_list = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        pdf_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Check if it's a PDF file\n",
    "        if os.path.isfile(pdf_path) and pdf_path.lower().endswith('.pdf'):\n",
    "            # Get PDF information\n",
    "            pdf_info = get_pdf_info(pdf_path)\n",
    "            file_info_list.append(pdf_info)\n",
    "\n",
    "    # Create a DataFrame from the list of file information\n",
    "    pdf_file_info_df = pd.DataFrame(file_info_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "pdf_file_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea6f92c",
   "metadata": {},
   "source": [
    "**Saving DataFrames In Excel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95eafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = 'dataframes.xlsx'\n",
    "\n",
    "# Create an Excel writer object\n",
    "with pd.ExcelWriter(excel_file_path, engine='xlsxwriter') as writer:\n",
    "    # Write each DataFrame to a different sheet\n",
    "    pdf_file_info_df.to_excel(writer, sheet_name='PDF_Info', index=False)\n",
    "    image_file_info_df.to_excel(writer, sheet_name='Image_Info', index=False)\n",
    "    video_file_info_df.to_excel(writer, sheet_name='Video_Info', index=False)\n",
    "\n",
    "print(f'Excel file \"{excel_file_path}\" has been created with three sheets.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a694b-375c-4a75-9a54-3a756121e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a report summarizing the findings\n",
    "def generate_report(dataframes):\n",
    "    for df in dataframes:\n",
    "        # Create a simple text-based report\n",
    "        report = f\"{df} Data Analysis Report\\n\\n\"\n",
    "        report += \"Data Columns Info:\\n\"\n",
    "        report += str(df.info()) + \"\\n\\n\"\n",
    "        report += \"Summary Statistics:\\n\"\n",
    "        report += str(df.describe()) + \"\\n\\n\"\n",
    "        report += \"Correlation Matrix:\\n\"\n",
    "        report += str(df.corr) + \"\\n\"\n",
    "\n",
    "        # Save the report to a text file\n",
    "        with open('data_analysis_report.txt', 'w') as file:\n",
    "            file.write(report)\n",
    "\n",
    "        print(\"Data analysis report generated and saved.\")\n",
    "    else:\n",
    "        print(\"Analysis results are None. Cannot generate the report.\")\n",
    "\n",
    "all_dataframes = [image_file_info_df,video_file_info_df,pdf_file_info_df]\n",
    "generate_report(all_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51811d3-6646-46d5-948e-c8754a1d3977",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

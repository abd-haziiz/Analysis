{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9fb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Requirement already satisfied: opencv-python in c:\\users\\obadi\\anaconda3\\new folder\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\obadi\\anaconda3\\new folder\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "!pip install opencv-python --index-url=https://pypi.python.org/simple/\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ec56496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d7edd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0b9242",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DISK 2 videos: 100%|██████████| 1/1 [00:32<00:00, 32.53s/it]\n",
      "Processing DISK 3 videos: 100%|██████████| 1/1 [00:56<00:00, 56.76s/it]\n",
      "Processing DISK 4 videos: 100%|██████████| 1/1 [00:57<00:00, 57.38s/it]\n",
      "Processing DISK1 videos: 100%|██████████| 1/1 [01:08<00:00, 68.71s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # Optional: for progress tracking\n",
    "\n",
    "# Set the path to the directory containing your video files\n",
    "video_directory = 'C:/Users/obadi/Downloads/SECURE DEMOCRACY PRESIDENTIAL INAUGURATION-20231225T151306Z-001/AchivalVideos'\n",
    "\n",
    "# Create empty lists to store video frames and corresponding labels\n",
    "frames = []\n",
    "labels = []\n",
    "\n",
    "# Define a function to load and preprocess each video\n",
    "def load_and_preprocess_video(video_path, label):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    batch_size = 100  # Adjust the batch size based on available memory\n",
    "    frames_batch = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocess the frame if needed\n",
    "        # e.g., resize the frame to new_width and new_height\n",
    "        frame = cv2.resize(frame, (new_width, new_height))\n",
    "    frames_batch.append(frame)\n",
    "\n",
    "    if len(frames_batch) == batch_size:\n",
    "        process_frames(frames_batch, label)\n",
    "        frames_batch = []\n",
    "\n",
    "        frames.append(frame)\n",
    "        labels.append(label)\n",
    "\n",
    "    cap.release()  # Release resources after processing all frames\n",
    "\n",
    "# Specify the desired width and height for preprocessing\n",
    "new_width, new_height = 440, 280  # Adjust as needed\n",
    "\n",
    "# Iterate through each subdirectory (each class/label)\n",
    "for label in os.listdir(video_directory):\n",
    "    label_path = os.path.join(video_directory, label)\n",
    "\n",
    "    # Ensure it's a directory\n",
    "    if os.path.isdir(label_path):\n",
    "        # Iterate through video files in the subdirectory\n",
    "        for video_file in tqdm(os.listdir(label_path), desc=f\"Processing {label} videos\"):\n",
    "            video_path = os.path.join(label_path, video_file)\n",
    "\n",
    "            # Load and preprocess the video\n",
    "            load_and_preprocess_video(video_path, label)\n",
    "\n",
    "# Convert frames and labels to NumPy arrays for further processing\n",
    "frames = np.array(frames)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Optionally, you may want to shuffle the data\n",
    "indices = np.arange(len(frames))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "frames = frames[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# Define the process_frames function or replace it with your processing logic\n",
    "def process_frames(frames_batch, label):\n",
    "    # Your processing logic here\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970017bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = np.array([\n",
    "    [\"DISK 1\", AVSEQ01],\n",
    "    [\"DISK 2\", AVSEQ02],\n",
    "    [\"DISK 3\", AVSEQ03],\n",
    "    [\"DISK 4\", AVSEQ04]\n",
    "])\n",
    "\n",
    "# Example: Labels (output variable)\n",
    "# In this example, each element represents the label for the corresponding data point.\n",
    "# You need to replace this with the actual labels from your dataset.\n",
    "labels = np.array([\"DISK 1\", \"DISK 2\", \"DISk 3\",\"DISk 4\"])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e017c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels if necessary\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)-\n",
    "+\n",
    "\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8215223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the machine learning model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f55cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43693727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1303ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "predictions = model.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
